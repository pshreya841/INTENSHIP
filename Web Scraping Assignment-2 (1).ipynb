{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30a0cafa",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 2\n",
    "\n",
    "using selenium in Jupyter NoteBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4587f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "873e2c50",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482c4cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leap COE Intern(Data Analyst)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Info Origin Inc.</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - Data Science, 3 To 5 Years</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Rise Finconnect</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst, plsql, Tableau, Informatica</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst / MIS</td>\n",
       "      <td>Bangalore/Bengaluru(Indira Nagar)</td>\n",
       "      <td>Trukker Technologies</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst - SQL/Tableau</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Global Employees</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - Data Visualization &amp; Reporting</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Global Employees</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Remote</td>\n",
       "      <td>LINGARO INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - EdTech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TalentStack</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job-title   \\\n",
       "0                            Senior Data Analyst   \n",
       "1                  Leap COE Intern(Data Analyst)   \n",
       "2      Data Analyst - Data Science, 3 To 5 Years   \n",
       "3      Data Analyst, plsql, Tableau, Informatica   \n",
       "4                             Data Analyst / MIS   \n",
       "5              Senior Data Analyst - SQL/Tableau   \n",
       "6                         Senior Data Analyst II   \n",
       "7  Data Analyst - Data Visualization & Reporting   \n",
       "8                                   Data Analyst   \n",
       "9                          Data Analyst - EdTech   \n",
       "\n",
       "                                        job-location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4                  Bangalore/Bengaluru(Indira Nagar)   \n",
       "5  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "8                                             Remote   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                    company_name experience_required  \n",
       "0                          Optum             5-7 Yrs  \n",
       "1               Info Origin Inc.             0-1 Yrs  \n",
       "2                Rise Finconnect             2-6 Yrs  \n",
       "3                      Capgemini             3-8 Yrs  \n",
       "4           Trukker Technologies             3-6 Yrs  \n",
       "5               Global Employees            7-12 Yrs  \n",
       "6                       Flipkart             3-6 Yrs  \n",
       "7               Global Employees            5-10 Yrs  \n",
       "8  LINGARO INDIA PRIVATE LIMITED             3-5 Yrs  \n",
       "9                    TalentStack             2-6 Yrs  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,'//input[@placeholder=\"Enter location\"]')\n",
    "location.send_keys('Bangalore')\n",
    "\n",
    "search=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "job_company=[]\n",
    "job_experience=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    cname=i.text\n",
    "    job_company.append(cname)\n",
    "\n",
    "\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i  in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    job_experience.append(experience)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "dataAnalyst=pd.DataFrame({'job-title ':job_title,'job-location':job_location,'company_name':job_company,'experience_required':job_experience})\n",
    "dataAnalyst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b30e0e9c",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ef0f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expert Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Full Stack</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>Salesforce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BCAI - Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bosch Global Software Technologies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job-title   \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "2                   Assistant Manager - Data Science   \n",
       "3     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "4                        Data Science Senior Analyst   \n",
       "5  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "6                              Expert Data Scientist   \n",
       "7  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "8                        Data Scientist - Full Stack   \n",
       "9                       BCAI - Senior Data Scientist   \n",
       "\n",
       "                                        job-location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "1  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "2                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "3  Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "5  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "6                        Bangalore/Bengaluru, Mumbai   \n",
       "7  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "8        Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                  company_name  \n",
       "0                                    Accenture  \n",
       "1                                        Wipro  \n",
       "2                                   CitiusTech  \n",
       "3              TATA CONSULTANCY SERVICES (TCS)  \n",
       "4                                    Accenture  \n",
       "5  NTT DATA Business Solutions Private Limited  \n",
       "6                    United Phosphorus Limited  \n",
       "7                                        Wipro  \n",
       "8                                   Salesforce  \n",
       "9           Bosch Global Software Technologies  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,'//input[@placeholder=\"Enter location\"]')\n",
    "location.send_keys('Bangalore')\n",
    "\n",
    "search=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "job_company=[]\n",
    "job_experience=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    cname=i.text\n",
    "    job_company.append(cname)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "dataScientist=pd.DataFrame({'job-title ':job_title,'job-location':job_location,'company_name':job_company})\n",
    "dataScientist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00fc1ef8",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4576bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Delhi / NCR, Kochi/Cochin, Indore, New Delhi, ...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Ghaziabad, Gurgaon/Gurugram</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring Of Data Science Intern</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>FLIP ROBO TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugram</td>\n",
       "      <td>Care Health Insurance (CHI)</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugra...</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>PRASU SOFTWARE SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       job-title   \\\n",
       "0  Data scientist _Tata Consultancy Services(Tcs)   \n",
       "1                                  Data Scientist   \n",
       "2                   Hiring Of Data Science Intern   \n",
       "3      Data Scientist For Healthcare Product team   \n",
       "4      Data Scientist For Healthcare Product team   \n",
       "5                           Data Scientist Intern   \n",
       "6                                  Data Scientist   \n",
       "7                        Knowledge/Data Scientist   \n",
       "8                                    Data Science   \n",
       "9                                  Data Scientist   \n",
       "\n",
       "                                        job-location  \\\n",
       "0  Delhi / NCR, Kochi/Cochin, Indore, New Delhi, ...   \n",
       "1                 Noida, Ghaziabad, Gurgaon/Gurugram   \n",
       "2                         Noida, Bangalore/Bengaluru   \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "5    Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugram   \n",
       "6             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "7                                        Delhi / NCR   \n",
       "8  Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugra...   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                               company_name experience_required  \n",
       "0           TATA CONSULTANCY SERVICES (TCS)            9-14 Yrs  \n",
       "1                                   Genpact            6-10 Yrs  \n",
       "2    FLIP ROBO TECHNOLOGIES PRIVATE LIMITED             0-2 Yrs  \n",
       "3                  SECUREKLOUD TECHNOLOGIES             2-7 Yrs  \n",
       "4                  SECUREKLOUD TECHNOLOGIES             2-7 Yrs  \n",
       "5               Care Health Insurance (CHI)             0-0 Yrs  \n",
       "6   Mount Talent Consulting Private Limited             2-4 Yrs  \n",
       "7                   BOLD Technology Systems             3-6 Yrs  \n",
       "8   Mount Talent Consulting Private Limited             2-5 Yrs  \n",
       "9  PRASU SOFTWARE SOLUTIONS PRIVATE LIMITED             2-4 Yrs  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "#location=driver.find_element(By.XPATH,'//input[@placeholder=\"Enter location\"]')\n",
    "#location.send_keys('Bangalore')\n",
    "search=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH,\"//span[@title='Delhi / NCR']\").click()\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH,\"//span[@title='0-3 Lakhs']\").click()\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "job_company=[]\n",
    "job_experience=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    cname=i.text\n",
    "    job_company.append(cname)\n",
    "\n",
    "\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i  in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    job_experience.append(experience)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "data_ScientistLoc=pd.DataFrame({'job-title ':job_title,'job-location':job_location,'company_name':job_company,'experience_required':job_experience})\n",
    "data_ScientistLoc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9d7864d",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "\n",
    "2. Product Description\n",
    "\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46cb4418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Retro Square Sunglasses (61)</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection, Polarized Aviator S...</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>₹194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Gradient, UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹1,415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product Description   Price\n",
       "0       ROYAL SON             Polarized Retro Square Sunglasses (61)    ₹699\n",
       "1   VINCENT CHASE  by Lenskart UV Protection, Polarized Aviator S...    ₹949\n",
       "2        DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...    ₹194\n",
       "3        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹599\n",
       "4        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹359\n",
       "..            ...                                                ...     ...\n",
       "95  VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹949\n",
       "96     LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...    ₹179\n",
       "97         GANSTA    Gradient, UV Protection Aviator Sunglasses (57)    ₹296\n",
       "98       Fastrack        UV Protection Shield Sunglasses (Free Size)    ₹669\n",
       "99  VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...  ₹1,415\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "except NoSuchElementException:\n",
    "    print('No login pop-up')\n",
    "    \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]').send_keys('sunglasses')\n",
    "driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]').click()\n",
    "\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "for page in range(0,3):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags[0:100]:\n",
    "        brandName=i.text\n",
    "        brand.append(brandName)\n",
    "    \n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for j in product_tags[0:100]:\n",
    "        productD=j.text\n",
    "        product_description.append(productD)\n",
    "        \n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for k in price_tags[0:100]:\n",
    "        price_t=k.text\n",
    "        price.append(price_t)\n",
    "    \n",
    "time.sleep(3)\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"ge-49M\"]')\n",
    "next_page.click\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "sunglasses_df=pd.DataFrame({'Brand':brand[0:100],'Product Description':product_description[0:100],'Price':price[0:100]})\n",
    "sunglasses_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f618c1d",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "\n",
    "3. Then click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92ebb943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5   Highly recommended   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Fabulous!   \n",
       "96      5        Great product   \n",
       "97      5    Worth every penny   \n",
       "98      5   Highly recommended   \n",
       "99      4          Good choice   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first iOS phone. I am very happy wi...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  It's my first time to use iOS phone and I am l...  \n",
       "99  So far it’s been an AMAZING experience coming ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "except NoSuchElementException:\n",
    "    print('No login pop-up')\n",
    "    \n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]').send_keys('iphone11')\n",
    "driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]').click()\n",
    "\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH,'//div[@class=\"_4rR01T\"]').click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "driver.find_element(By.XPATH,'//div[@class=\"_3UAT2v _16PBlm\"]/span').click()\n",
    "\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    \n",
    "    rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tag[0:100]:\n",
    "        rating_all=i.text\n",
    "        rating.append(rating_all)\n",
    "    \n",
    "    summary_rs=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in summary_rs[0:100]:\n",
    "        summary_review=i.text\n",
    "        review_summary.append(summary_review)\n",
    "    \n",
    "    review_full=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div/div')\n",
    "    for i in review_full[0:100]:\n",
    "        review_fullAll=i.text\n",
    "        full_review.append(review_fullAll)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]/span')\n",
    "next_page.click\n",
    "time.sleep(3)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "review_in_deep=pd.DataFrame({'Rating':rating,'Review summary':review_summary,'Full review':full_review})\n",
    "review_in_deep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e11201e",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "1. Brand\n",
    "\n",
    "2. Product Description\n",
    "\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb5c8283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹424</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KRAFTER</td>\n",
       "      <td>Krafter denim jeans Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>supr Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Puma Smash v2 Sneakers For Men</td>\n",
       "      <td>₹2,085</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ONECENTRE</td>\n",
       "      <td>STR2 Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Red Rose</td>\n",
       "      <td>supr Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Smash Wns v2 L Sneakers For Women</td>\n",
       "      <td>₹179</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Levi's Men's Lancer Sneakers Sneakers For Men</td>\n",
       "      <td>₹1,645</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LEVI'S</td>\n",
       "      <td>Casual Sneaker for Men Sneakers For Men</td>\n",
       "      <td>₹1,439</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>pollachief</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹503</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                            Product Description   Price Discount\n",
       "0    ROCKFIELD                               Sneakers For Men    ₹424  57% off\n",
       "1      KRAFTER           Krafter denim jeans Sneakers For Men    ₹499  50% off\n",
       "2       Layasa                          supr Sneakers For Men    ₹199  80% off\n",
       "3         PUMA                 Puma Smash v2 Sneakers For Men  ₹2,085  58% off\n",
       "4    ONECENTRE                          STR2 Sneakers For Men    ₹299  50% off\n",
       "..         ...                                            ...     ...      ...\n",
       "95    Red Rose                          supr Sneakers For Men    ₹499  55% off\n",
       "96      Layasa              Smash Wns v2 L Sneakers For Women    ₹179  49% off\n",
       "97        PUMA  Levi's Men's Lancer Sneakers Sneakers For Men  ₹1,645  74% off\n",
       "98      LEVI'S        Casual Sneaker for Men Sneakers For Men  ₹1,439  71% off\n",
       "99  pollachief                               Sneakers For Men    ₹503  64% off\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(3)\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "except NoSuchElementException:\n",
    "    print('No login pop-up')\n",
    "    time.sleep(2)\n",
    "\n",
    "driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]').send_keys('sneakers')\n",
    "driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]').click()\n",
    "\n",
    "time.sleep(3)\n",
    "sneakers_brand=[]\n",
    "sneakers_prodDesc=[]\n",
    "sneakers_price=[]\n",
    "sneaker_discount=[]\n",
    "time.sleep(3)\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    sBrand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in sBrand_tags[0:100]:\n",
    "        s_brand=i.text\n",
    "        sneakers_brand.append(s_brand)\n",
    "    \n",
    "    s_prodD=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "    s_prodD1=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    \n",
    "    for i in s_prodD1[0:100]:\n",
    "        sprod_d1=i.text\n",
    "        sneakers_prodDesc.append(sprod_d1)\n",
    "    \n",
    "    for i in s_prodD[0:100]:\n",
    "        sprod_d=i.text\n",
    "        sneakers_prodDesc.append(sprod_d)\n",
    "    \n",
    "    s_price=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in s_price[0:100]:\n",
    "        sprice=i.text\n",
    "        sneakers_price.append(sprice)\n",
    "        \n",
    "    sneaker_disc=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]/span')\n",
    "    for i in sneaker_disc[0:100]:\n",
    "        s_disc=i.text\n",
    "        sneaker_discount.append(s_disc)\n",
    "        \n",
    "time.sleep(3)\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]/span')\n",
    "next_page.click\n",
    "time.sleep(3)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "sneakers_dataframe=pd.DataFrame({'Brand':sneakers_brand[0:100],'Product Description':sneakers_prodDesc[0:100],'Price':sneakers_price[0:100],'Discount':sneaker_discount[0:100]})\n",
    "sneakers_dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e328fcf",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdc3e4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>[Rs., 7199Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "      <td>[Rs., 11196Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO FLEX 2-COMPLETION Shoes</td>\n",
       "      <td>[Rs., 7499]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Niteball II Sneakers</td>\n",
       "      <td>[Rs., 9349Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>[Rs., 7649Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Leather Derbys</td>\n",
       "      <td>[Rs., 7499]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Woven NMD_31 Sneakers</td>\n",
       "      <td>[Rs., 11199Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Accelerate Badminton</td>\n",
       "      <td>[Rs., 7199Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Ozweego Sneakers</td>\n",
       "      <td>[Rs., 10999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Lockdown 5 Basketball</td>\n",
       "      <td>[Rs., 6999]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand             Product Description            Price\n",
       "0           Skechers      Men Max Cushioning Running   [Rs., 7199Rs.]\n",
       "1               Nike    Men React Infinity 3 Running  [Rs., 11196Rs.]\n",
       "2           Skechers  Men GO FLEX 2-COMPLETION Shoes      [Rs., 7499]\n",
       "3   ADIDAS Originals        Men Niteball II Sneakers   [Rs., 9349Rs.]\n",
       "4           Skechers      Men Max Cushioning Running   [Rs., 7649Rs.]\n",
       "..               ...                             ...              ...\n",
       "95            Clarks              Men Leather Derbys      [Rs., 7499]\n",
       "96  ADIDAS Originals       Men Woven NMD_31 Sneakers  [Rs., 11199Rs.]\n",
       "97              Puma     Unisex Accelerate Badminton   [Rs., 7199Rs.]\n",
       "98  ADIDAS Originals            Men Ozweego Sneakers     [Rs., 10999]\n",
       "99      UNDER ARMOUR       Men Lockdown 5 Basketball      [Rs., 6999]\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "\n",
    "time.sleep(5)\n",
    "driver.find_element(By.XPATH,'//span[@data-colorhex=\"black\"]').click()\n",
    "time.sleep(5)\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label').click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "shoe_brand=[]\n",
    "shoe_desc=[]\n",
    "shoe_price=[]\n",
    "\n",
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    shoeB_tags=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in shoeB_tags[0:100]:\n",
    "        s_brand=i.text\n",
    "        shoe_brand.append(s_brand)\n",
    "        \n",
    "    shoeD_tags=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in shoeD_tags[0:100]:\n",
    "        s_desc=i.text\n",
    "        shoe_desc.append(s_desc)\n",
    "        \n",
    "    shoeP_tags=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in shoeP_tags[0:100]:\n",
    "        s_price=i.text.split(\" \")[0:2]\n",
    "        shoe_price.append(s_price)\n",
    "    \n",
    "time.sleep(3)\n",
    "next_button=driver.find_element(By.XPATH,'//a[@rel=\"next\"]')\n",
    "next_button.click\n",
    "time.sleep(3)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "myntra_shoe=pd.DataFrame({'Brand':shoe_brand,'Product Description':shoe_desc,'Price':shoe_price})\n",
    "myntra_shoe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18c4453f",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "    \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "    \n",
    "1. Title\n",
    "\n",
    "2. Ratings\n",
    "\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f1be587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>₹79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 Pro 360 Intel 12th Gen i7...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>₹1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>₹79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>₹89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>₹54,848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>₹82,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>₹87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>₹84,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  3.6 out of 5 stars   \n",
       "1  Samsung Galaxy Book2 Pro 360 Intel 12th Gen i7...  3.5 out of 5 stars   \n",
       "2  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...  3.9 out of 5 stars   \n",
       "3  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  5.0 out of 5 stars   \n",
       "4  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  3.6 out of 5 stars   \n",
       "5  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.2 out of 5 stars   \n",
       "6  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.7 out of 5 stars   \n",
       "7  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...  4.0 out of 5 stars   \n",
       "8  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...  3.9 out of 5 stars   \n",
       "9  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...  4.5 out of 5 stars   \n",
       "\n",
       "       Price  \n",
       "0    ₹79,490  \n",
       "1  ₹1,29,990  \n",
       "2    ₹59,990  \n",
       "3    ₹81,990  \n",
       "4    ₹79,490  \n",
       "5    ₹89,990  \n",
       "6    ₹54,848  \n",
       "7    ₹82,400  \n",
       "8    ₹87,990  \n",
       "9    ₹84,990  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "textBox=driver.find_element(By.ID,'twotabsearchtextbox')\n",
    "textBox.send_keys('Laptop')\n",
    "\n",
    "submit=driver.find_element(By.ID,'nav-search-submit-button')\n",
    "submit.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "cpu_type=driver.find_element(By.XPATH,'//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span')\n",
    "cpu_type.click()\n",
    "\n",
    "time.sleep(3)\n",
    "product_title=[]\n",
    "product_rating=[]\n",
    "product_price=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    product_title.append(i.text)\n",
    "    \n",
    "product_tags=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "for i in product_tags[0:10]:\n",
    "    rating=i.get_attribute('aria-label')\n",
    "    product_rating.append(rating)\n",
    "    \n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    product_price.append(i.text)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "laptop_dataFrame=pd.DataFrame({'Title':product_title,'Rating':product_rating,'Price':product_price})\n",
    "laptop_dataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49cc9328",
   "metadata": {},
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65a5976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table not found on the webpage.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.jagranjosh.com/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "gk_link = soup.find('a', text='GK')['href']\n",
    "gk_url = url + gk_link\n",
    "gk_response = requests.get(gk_url)\n",
    "gk_soup = BeautifulSoup(gk_response.content, 'html.parser')\n",
    "\n",
    "table = gk_soup.find('table', class_='table4')\n",
    "if table:\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        columns = row.find_all('td')\n",
    "        name = columns[0].text.strip()\n",
    "        born_dead = columns[1].text.strip()\n",
    "        term_of_office = columns[2].text.strip()\n",
    "        remarks = columns[3].text.strip()\n",
    "        data.append([name, born_dead, term_of_office, remarks])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Born-Dead', 'Term of Office', 'Remarks'])\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Table not found on the webpage.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b58a8ac0",
   "metadata": {},
   "source": [
    "Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. \n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3278aacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link not found on the search results page.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.motor1.com/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "search_bar = soup.find('input', {'name': 'q'})\n",
    "search_bar['value'] = '50 most expensive cars'\n",
    "\n",
    "form = search_bar.find_parent('form')\n",
    "search_url = url + form['action']\n",
    "response = requests.get(search_url, params={'q': '50 most expensive cars'})\n",
    "search_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "link = search_soup.find('a', text='50 Most Expensive Cars in the World')\n",
    "\n",
    "if link:\n",
    "    exp_cars_url = url + link['href']\n",
    "    exp_cars_response = requests.get(exp_cars_url)\n",
    "    exp_cars_soup = BeautifulSoup(exp_cars_response.content, 'html.parser')\n",
    "\n",
    "    cars_container = exp_cars_soup.find('div', class_='article-text')\n",
    "    car_items = cars_container.find_all('div', class_='item')\n",
    "\n",
    "    data = []\n",
    "    for car in car_items:\n",
    "        name = car.find('a').text.strip()\n",
    "        price = car.find('span', class_='price').text.strip()\n",
    "        data.append([name, price])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Car Name', 'Price'])\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Link not found on the search results page.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
